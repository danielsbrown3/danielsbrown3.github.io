<!DOCTYPE html>
<html>

  <head>
<link href='./style.css' rel = 'stylesheet'>
    
  </head>
<body>
<h1 class='title'>Daniel Brown</h1>
<p>I'm hosted with Github Pages. Hi I'm Daniel and I Love to read. This website will document the thoughts 
  and feelings I have about current books I am reading.</p>
<h2 class='title'>Books Currently Reading</h2>
  <h3 class='title'> <em>A Thousand Brains by</em> Jeff Hawkins </h3>
  <p> I'm currently reading <em>A Thousand Brains</em> by Jeff Hawkins about the neuroscience behind the brain and how that informs technology.
    The introduction of the book starts as <span>Jeff Hawkins</span> lays the groundwork of his career. <br> <br> His career is very inspiring, he started as an aspiring
    neuroscientist student who was denied his <strong>PHD</strong> at Berkeley. After being denied he created his own venture into neurology research and shortly after went
    into the computing industry in silicon valley. He founded Palm Computing which produced the first computing tablet. He shortly after continued his journey into 
    neurology by founding the company Numenta. <br> 
    <b>Part 1  - "A New Understanding of the Brain"</b>
    Defines what intelligence is and how incredible it is that a collection of cells in our brain can make models of the world and consistently update those models.
    Intelligence is the ability to create and update models in your brain. The other then goes on to decscibe that there are two portions of the brain, the repitlian
     "old brain" and the Neocortex. The reptilian old brain is responsible for keeping us alive and reproducing, preserving our genes. The Neocortex, a sheet of cells
    that wraps fully around the brain for miles at a time. Jeff also describes his life story as to provide an ethos for the reader on why to trust the claims he is 
    making. His life is quite incredible, he started working at the early days of Intel, then pursued neuroscience research, was rejected by every big university, studied
    on his own for 2 years, started a computer company Palm Computing, was very successful, resumed his neorology research with Numenta. <br>
    <b> Chapter 1 - "Old Brain-New Brain"</b>
    A more in depth view of the old brain and Neocortex. The Neocortex cannot control movement, only the old brain can. The Neocortex must overcome the urges of the old
    brain in order to complete any actions. This is why it is difficult for humans to resist sex, high sugar and fat foods, and things that will help reproduce. The Neocortex
    is structured like a computer, control boxes with input and outputs leading to different control boxes. There are sections of the brain that are dedicated to vision, smell
    etc. However, the author argues that even though there are sections of the brain dedicated towards those functions, the cells are not built specifically for that 
    function. All brain cells are built the same, to create models. For example, there was a study conducted on a frog where scientists added a third eye to the frogs
    head. Instead of the vision sector of the brain supporting those cells, cells from all other sensing parts of the frogs brain supported the eye. Therefore any part
    of the brain can be used for any sensation, because they are all just model cells. <br> 
    <b>Chapter 2 - "Vernon Mountcastle's Big Idea"</b>
    Neocortex did not evolve to produce cells for a specific task, rather it just kept producing more and more of the same brain cells and found uses for them. Hawkins
    unveils one of his theories: cortical columns (long columns of brain cells interconnected in the brain) are algortihms as evident by similair circuits, evolved in a short amount of time, 
    can be adapted to any sensory input, and the fact that humans are capable of so many unrelated task. <br> 
    <b>Chapter 3- "A Model of the World in Your Head"</b>
    Neocortex works by modeling -> predicting -> checking error. The brain is constantly running a feedback loop that responds to the changing world and us moving 
    ourselves. To learn you must get error and create new model. The numnber of neurons in your brain that are active at the same time is around 2% (maybe I shouldn't
    multitask since I only have 2% avaialbe to me). Synaspes in the brain that store memories or "models" are strengthened or weakened, rather they are created or
    destroyed.  <br>
    <b>Chapter 4- "The Brain Reveal Its Secrets"</b> 
    Anything can be learned if humans have learned it. No predictor neurons, when holding a cup we are not aware of the cup. Our brain has to predict the world and then
    predict how it can manipulate it. 90% of synapses, the small little hairs (not hairs but looks like it) along the neurons that recieve input, are located on dendrites.
    Dendrites are the roots that expand out of the neuron and connect to other neurons. 
    IMPORTANT- In this chapter it desribes how electrical signals determine how we learn, I think this is one of the most important ideas in the book. Page 46.
    Some neurons in the brain, already have a model for something we've learned before. Once the brain recieves that similair input, the neurons that have that model will
    fire first and all other neurons will not fire. However, if there is something that you have not learned before, or seen before, there is no neurons that already have
    that model stored. So all neurons will fire at the same time on what model they think that new thing is. The model that gets the most neurons firing on the same thing
    is the model that is accepted. <br>
    <b>Chapter 5- "Maps in the Brain"</b>
    
    <b>My first machine learning code 8/5/2023:</b>
    I created my first code! With a step by step tutorial of course, so hopefully I can adapt it to be my own soon. However, to make sure my dendrites create an 
    accurate model of what I learned, I'm going to try and teach it to myself here.  <br>
    First lets describe what a machine learning model really is: <br>
    <li>1. Recieves data as input</li>
    <li>2. Manipulates the inputs in a hidden layer by applying weights and bias</li>
    <li>3. Spits out an output as a result.</li>
    <li>4. Assesses the error of the output compared with the initial data.</li>
    <li>5. Uses an algorithms to reduce the error and iterate.</li> <br>
    Now that we know an overview, lets discuss how to accomplish it. First, we want to push the data through our layers and get an output using Forward Propagation.
    y = w *(dot product) x + b. Where y is the output, x is the input, w are the randomly generated weights, and b is the bias. y,x, and w are arrays and b is a scalar.
    Once we have our output y from applying our weights and bias, we want to compute the error, dE/dy. The error can be computed using the Mean Squared Error equation: 
    dE/dy = 2 / (total number of outputs) * [correct output[i] - predicted output[i]]. Where i corresponds to which element you are computing the error of. One you have DE/dy
    you can begin Back Propagation. Where you start from the output and work your way backwards computing error such that you can accomplish gradient descent and change 
    the weights and biases to reduce error. To accomplish back propagation, need to also computer dE/dx (change in error with respect to x), dE/dB(change in error with 
    respect to bias), and dE/dw(change in error with respect to weights. The derviation of each of these values involves the chain rule, dE/dx = dE/dy * dy/dx. 
    dE/dB = dE/dy * dy/dB. dE/dw = dE/dy * dy/dw. Where the dy/d(insert) derivation is found from the equation y = w * x + b. The neural network also needs an activation
    layer which basically a nonlinear componenet to make the model more accurate. The nonlinear activation layer I used was tanh(x), for this layer you do element wise 
    multiplication. (I am a little unsure about this part as I'm not sure if this activation layer is a completely different model or apart of the current linear model)
    ->Research activation layer and nonlinear models<-
  </p>
</body>
</html>
