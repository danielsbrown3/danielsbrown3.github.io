<!DOCTYPE html>
<html>

  <head>
<link href='./style.css' rel = 'stylesheet'>
    
  </head>
<body>
<h1 class='title'>Daniel Brown</h1>
<p>I'm hosted with Github Pages. Hi I'm Daniel and I Love to read. This website will document the thoughts 
  and feelings I have about current books I am reading.</p>
<h2 class='title'>Books Currently Reading</h2>
  <h3 class='title'> <em>A Thousand Brains by</em> Jeff Hawkins </h3>
  <p> I'm currently reading <em>A Thousand Brains</em> by Jeff Hawkins about the neuroscience behind the brain and how that informs technology.
    The introduction of the book starts as <span>Jeff Hawkins</span> lays the groundwork of his career. <br> <br> His career is very inspiring, he started as an aspiring
    neuroscientist student who was denied his <strong>PHD</strong> at Berkeley. After being denied he created his own venture into neurology research and shortly after went
    into the computing industry in silicon valley. He founded Palm Computing which produced the first computing tablet. He shortly after continued his journey into 
    neurology by founding the company Numenta. <br> 
    <b>Part 1  - "A New Understanding of the Brain"</b>
    Defines what intelligence is and how incredible it is that a collection of cells in our brain can make models of the world and consistently update those models.
    Intelligence is the ability to create and update models in your brain. The other then goes on to decscibe that there are two portions of the brain, the repitlian
     "old brain" and the Neocortex. The reptilian old brain is responsible for keeping us alive and reproducing, preserving our genes. The Neocortex, a sheet of cells
    that wraps fully around the brain for miles at a time. Jeff also describes his life story as to provide an ethos for the reader on why to trust the claims he is 
    making. His life is quite incredible, he started working at the early days of Intel, then pursued neuroscience research, was rejected by every big university, studied
    on his own for 2 years, started a computer company Palm Computing, was very successful, resumed his neorology research with Numenta. <br>
    <b> Chapter 1 - "Old Brain-New Brain"</b>
    A more in depth view of the old brain and Neocortex. The Neocortex cannot control movement, only the old brain can. The Neocortex must overcome the urges of the old
    brain in order to complete any actions. This is why it is difficult for humans to resist sex, high sugar and fat foods, and things that will help reproduce. The Neocortex
    is structured like a computer, control boxes with input and outputs leading to different control boxes. There are sections of the brain that are dedicated to vision, smell
    etc. However, the author argues that even though there are sections of the brain dedicated towards those functions, the cells are not built specifically for that 
    function. All brain cells are built the same, to create models. For example, there was a study conducted on a frog where scientists added a third eye to the frogs
    head. Instead of the vision sector of the brain supporting those cells, cells from all other sensing parts of the frogs brain supported the eye. Therefore any part
    of the brain can be used for any sensation, because they are all just model cells. <br> 
    <b>Chapter 2 - "Vernon Mountcastle's Big Idea"</b>
    Neocortex did not evolve to produce cells for a specific task, rather it just kept producing more and more of the same brain cells and found uses for them. Hawkins
    unveils one of his theories: cortical columns (long columns of brain cells interconnected in the brain) are algortihms as evident by similair circuits, evolved in a short amount of time, 
    can be adapted to any sensory input, and the fact that humans are capable of so many unrelated task. <br> 
    <b>Chapter 3- "A Model of the World in Your Head"</b>
    Neocortex works by modeling -> predicting -> checking error. The brain is constantly running a feedback loop that responds to the changing world and us moving 
    ourselves. To learn you must get error and create new model. The numnber of neurons in your brain that are active at the same time is around 2% (maybe I shouldn't
    multitask since I only have 2% avaialbe to me). Synaspes in the brain that store memories or "models" are strengthened or weakened, rather they are created or
    destroyed.  <br>
    <b>Chapter 4- "The Brain Reveal Its Secrets"</b> 
    Anything can be learned if humans have learned it. No predictor neurons, when holding a cup we are not aware of the cup. Our brain has to predict the world and then
    predict how it can manipulate it. 90% of synapses, the small little hairs (not hairs but looks like it) along the neurons that recieve input, are located on dendrites.
    Dendrites are the roots that expand out of the neuron and connect to other neurons. 
    IMPORTANT- In this chapter it desribes how electrical signals determine how we learn, I think this is one of the most important ideas in the book. Page 46.
    Some neurons in the brain, already have a model for something we've learned before. Once the brain recieves that similair input, the neurons that have that model will
    fire first and all other neurons will not fire. However, if there is something that you have not learned before, or seen before, there is no neurons that already have
    that model stored. So all neurons will fire at the same time on what model they think that new thing is. The model that gets the most neurons firing on the same thing
    is the model that is accepted. <br>
    <b>Chapter 5- "Maps in the Brain"</b> 
    I enjoyed this chapter because it addresses an idea that I haven't put much thought into: perception. How does our brain keep
    track of everything in the physical world? How does it keep your organs operational while creating a model of the enviorment 
    around me while still being able to cognitivelly think? An earth worm does not know the enviorment around it, rather it senses
    temparture and humidity and moves towards it. Such a simple computational algorithm, yet earth worms have survived millions of 
    years of evolution. The author continues on to describe grid cells and place cells, which are a little conceptially difficult for
    me to understand, but I'll try my best. From what I understood, place cells are cells that create the model of what you observe
    using sensory inputs, whereas grid cells are cells that control your perception of where you are with respect to the place cells
    model. For example, if I'm at a Chiptole, my place cells would represent the counter, bathroom, the sleek metal counter, the aroma
    of chicken, and my grid cells would be where my body is with respect to the chipotle my heart is in my chest my brain is in my 
    head etc. <br>
    <b>Chapter 6- "Concepts, Language, and High-Level Thinking"</b>
    High level thinking occurs in the same cells as sensory input. How do we make models for things we cannot see? How can I make a
    model for democracy? That is not something I can physically see in the world. Due to this conutrum, we can conclude that abstract
    thoughts that are not physical models are also stored in the same cells that physical models are. There is no difference in the cells
    that store each of the ideas. The brain is very organized with grid cells and place cells and cortical columns. Thinking in the brain
    are neurons sorting through reference frames (the frames produced by creating a model with place and grid cells). It is possible
    to store new thoughts on old reference frames, but that is usually not how it works. New ones are usually created and old ones deleted
    The brain moves linear to create a model just as your brain moves linearly to remember what the inside of your house looks like. 
    Thinking is just moving through neurons in your brain, when you've thought of something before, your brain stores that at a coordinate
    in your brain, and once you think of it again it begins moving at that coordinate. When we don't know a coordinate to start at we 
    become confused. Our brain hyperlinks to other parts of the brain. Reptile brain creates maps of enviorments. Neocortex describes
    what and where objects are in those enviorments and also creates maps of concepts. Its not about having a big brain, its about organizing
    the thoughts in your brain that matters. <br>
    <b>Chapter 7- "The Thousand Brains Theory of Intelligence"</b>
    The brain works like the Ford assembly line, in order for the eyes to "see" something it goes through multiple stages. Stage 1 could
    consist of seeing lines. Stage 2 could be responsible for corners. Stage 3 could be responsible for creating the whole image etc.
    The world our eyes see is not the perception of the world. Its probably 70% of the world we actually see. The other 30% is filled in 
    by our brain. Its not the size of the camera that matters, its the size of the processor. Knowledge is neither stored everywhere or in 
    a single cortical column. It is distributed amongst large amounts of cortical columns in clusters. Since knowledge is distributed 
    amongnst thousands of cortical columns, how do we see a single perception? The author hypothesizes that the columns vote. Process voting occurs.
    The best way I can explain this is with an analogy the author uses, a hand holding a coffee cup. Using one finer, you might be able to determine
    what the coffee cup is, but it will take a lot of work and time. However with 5 fingers, each one can vote on what it thinks the coffee cup
    is and the majority will most likely be right. Seizures occur when the brain cannot decide what the majority is and it tries to do every
    single thing at once. This is why doctors cut corticle column connections in the brain to stop seizures. Multi tasking is not good! Can only
    compute one model at once. <br>
    <b>Part 2- "Machine Intelligence"</b>
    Artificial Intelligence will be based off of the construction of the brain. Evolution is the best designed so trying to emulate
    nature in computes is inherently the best design. 
    <b>Chapter 8- "Why There Is Ni "I" in AI"</b>
    Machines are trained currently, they are not intelligent. They learn based on labeled data, on a very specific task. If you train
    a car on self driving, you can then ask it to fry and egg. It is not intelligence rather it is memorizing a pattern to a specific 
    subset of data and can't apply it to other subsets of data. Deep learning is not what the brain does currently, rather it is a pattern
    recognition algorithm that cannot adapt its patterns across categories. Knowledge representation is the leading problem for artificial
    intelligence. LLM's are great advancements in technology, but they are still fundamentally flawed compared to the Neocortex. Until 
    LLMs can learn models and not just a bunch of rules, they will not reach AGI. AI will develop as computers have. First computers, were
    very large and slow and specified for very specific tasks. Then as the price goes down, computers became to work on a lot of the same
    principles and universal computers that are able to network with other computers, compile code, etc are now the norm. The same
    tradjectory will follow with machine learning. The most important component of how the brain works is the neuron. When the neuron
    learns something new, it stores it on a synapse  that does not effect other synapses nearby. I don't understand why we cant just 
    cluster a bunch of machine learning devices together just like the brain clusters synapses together. Hawkins main argument is that until
    machines can learn continuously with deleting memory, learn via sensory input, abd stire tens of thousands of models it will not rival 
    the brain and it is not AGI. <br>
    <b>Chapter 9 - "When Machines Are Consicous"</b>
    
    

    
    <b>My first machine learning code 8/5/2023:</b>
    I created my first code! With a step by step tutorial of course, so hopefully I can adapt it to be my own soon. However, to make sure my dendrites create an 
    accurate model of what I learned, I'm going to try and teach it to myself here.  <br>
    First lets describe what a machine learning model really is: <br>
    <li>1. Recieves data as input</li>
    <li>2. Manipulates the inputs in a hidden layer by applying weights and bias</li>
    <li>3. Spits out an output as a result.</li>
    <li>4. Assesses the error of the output compared with the initial data.</li>
    <li>5. Uses an algorithms to reduce the error and iterate.</li> <br>
    Now that we know an overview, lets discuss how to accomplish it. First, we want to push the data through our layers and get an output using Forward Propagation.
    y = w *(dot product) x + b. Where y is the output, x is the input, w are the randomly generated weights, and b is the bias. y,x, and w are arrays and b is a scalar.
    Once we have our output y from applying our weights and bias, we want to compute the error, dE/dy. The error can be computed using the Mean Squared Error equation: 
    dE/dy = 2 / (total number of outputs) * [correct output[i] - predicted output[i]]. Where i corresponds to which element you are computing the error of. One you have DE/dy
    you can begin Back Propagation. Where you start from the output and work your way backwards computing error such that you can accomplish gradient descent and change 
    the weights and biases to reduce error. To accomplish back propagation, need to also computer dE/dx (change in error with respect to x), dE/dB(change in error with 
    respect to bias), and dE/dw(change in error with respect to weights. The derviation of each of these values involves the chain rule, dE/dx = dE/dy * dy/dx. 
    dE/dB = dE/dy * dy/dB. dE/dw = dE/dy * dy/dw. Where the dy/d(insert) derivation is found from the equation y = w * x + b. The neural network also needs an activation
    layer which basically a nonlinear componenet to make the model more accurate. The nonlinear activation layer I used was tanh(x), for this layer you do element wise 
    multiplication. (I am a little unsure about this part as I'm not sure if this activation layer is a completely different model or apart of the current linear model)
    ->Research activation layer and nonlinear models<-
  </p>
</body>
</html>
